---
title: "Hello, Quarto"
format: html
---

## Markdown

Markdown is an easy to read and write text format:

- It's _plain text_ so works well with version control
- It can be **rendered** into HTML, PDF, and more
- Learn more at: <https://quarto.org/docs/authoring/>

## Code Cell

Here is a Python code cell:

```{python}
import pandas as pd
import numpy as np
from lifelines import CoxPHFitter

df_time_to_cancer_dx = \
    pd.read_csv(
        "https://raw.githubusercontent.com/ddsjoberg/dca-tutorial/main/data/df_time_to_cancer_dx.csv"
    )

df_time_to_cancer_dx

cox_model = CoxPHFitter()
thin_model = CoxPHFitter()

# Fit the models
cox_model.fit(df_time_to_cancer_dx, duration_col='ttcancer', event_col='cancer', formula='age + famhistory + marker')
thin_model.fit(df_time_to_cancer_dx, duration_col='ttcancer', event_col='cancer', formula='age + marker')

reals_mapping = {
    "censor": 0,
    "diagnosed with cancer": 1,
    "dead other causes": 2
}
df_time_to_cancer_dx['reals'] = df_time_to_cancer_dx['cancer_cr'].map(reals_mapping)

# Predict risks at time 1.5
new_data = df_time_to_cancer_dx.copy()
new_data['ttcancer'] = 1.5
pred_1_5 = 1 - np.exp(-cox_model.predict_expectation(new_data))
pred_thin = 1 - np.exp(-thin_model.predict_expectation(new_data))

# Store probabilities
probs_cox = {
    "thin": pred_thin,
    "full": pred_1_5
}

fixed_time_horizons = [1, 3, 5]
stratified_by = ["probability_threshold", "ppcr"]

# Placeholder for create_aj_data_combinations
# aj_data_combinations = create_aj_data_combinations(list(probs_cox.keys()), fixed_time_horizons, stratified_by, 0.01)

# Create reference groups
# data_to_adjust = pd.DataFrame({
#     "reference_group": ["thin"] * len(probs_cox["thin"]) + ["full"] * len(probs_cox["thin"]),
#     "probs": np.concatenate([probs_cox["thin"], probs_cox["full"]]),
#     "reals": np.concatenate([df_time_to_cancer_dx['reals'], df_time_to_cancer_dx['reals']]),
#     "times": np.concatenate([df_time_to_cancer_dx['ttcancer'], df_time_to_cancer_dx['ttcancer']])
# })

# # Placeholder for add_cutoff_strata function
# data_to_adjust = add_cutoff_strata(data_to_adjust, by=0.01)

# data_to_adjust["reals"] = data_to_adjust["reals"].replace({
#     0: "real_negatives",
#     2: "real_competing",
#     1: "real_positives"
# })
# data_to_adjust["reals"] = pd.Categorical(data_to_adjust["reals"], categories=["real_negatives", "real_competing", "real_positives"], ordered=True)

# # Splitting data by reference group
# list_data_to_adjust = {k: v for k, v in data_to_adjust.groupby("reference_group")}

# # Define assumption sets
# assumption_sets = [
#     {"competing": "excluded", "censored": "excluded"},
#     {"competing": "adjusted_as_negative", "censored": "adjusted"},
#     {"competing": "adjusted_as_censored", "censored": "adjusted"},
#     {"competing": "excluded", "censored": "adjusted"},
#     {"competing": "adjusted_as_negative", "censored": "excluded"}
# ]

# # Adjust data based on assumptions
# adjusted_data_list = []
# for reference_group, group_data in list_data_to_adjust.items():
#     for assumptions in assumption_sets:
#         adjusted_data_list.append(
#             extract_aj_estimate_by_assumptions(
#                 group_data,
#                 censoring_assumption=assumptions["censored"],
#                 competing_assumption=assumptions["competing"],
#                 fixed_time_horizons=fixed_time_horizons
#             )
#         )

# # Combine adjusted data
# adjusted_data = pd.concat(adjusted_data_list, keys=list_data_to_adjust.keys(), names=["reference_group"])

# # Merge with aj_data_combinations
# adjusted_data = aj_data_combinations.merge(adjusted_data, on=[...])  # Define appropriate merge keys
```


